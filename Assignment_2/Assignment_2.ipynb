{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74d14dbf",
   "metadata": {},
   "source": [
    "## Motivation: \n",
    "\n",
    "The objective for the provided method is to solve two distinct tasks: sentiment analysis of reviews (task 1) and categorisation based on integrated data (task 2). Both tasks aim to create effective machine learning algorithms that can reliably assume the target variables. \n",
    "\n",
    "Task 1 focuses on assessing the sentiment of textual reviews, whilst task 2 seeks to categorize categories using features taken from both textual and numerical data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30ac4c1",
   "metadata": {},
   "source": [
    "### Data Preprocessing:\n",
    "The data for both tasks comprises of textual and numerical elements. Task 1 just uses textual review, whereas task 2 uses the combined feature. The textual data is preprocessed, which includes tokenization, stopword removal, lemmatization, and vectorization with CountVectorizer. Prior to preprocessing, numerical features are merged with textual data.\n",
    "\n",
    "In addition, I have test both 'CountVectorizer' and 'TfidfVectorizer' to vectorizating input data, After conducting tests with both 'CountVectorizer' and 'TfidfVectorizer' for vectorizing input data, it was observed that 'CountVectorizer' generally outperformed 'TfidfVectorizer' when used with the Bayes classifier, based on the formulated data; therefore we will using 'CountVectorizer' for our data preprocessing\n",
    "| |TifidVectorizer | CountVectorizer|\n",
    "|--|---------------|----------------|\n",
    "|CNB|0.8450704225352113|0.9084507042253521|\n",
    "|MNB|0.7288732394366197|0.8926056338028169|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4fb4c5",
   "metadata": {},
   "source": [
    "### Task 1: Sentiment Analysis\n",
    "For sentiment analysis (task 1), the data preprocessing stages are applied to the reviews, and the preprocessed data is divided into training and test sets using an 80-20 split (the most common comment splitting approach). The training data is used to train two Navie Bayes classifiers: Complement Navie Bayes and Multinomial Navie Bayes. Each classifier's accuracy is measured using the 'accuracy_score' metric on the test data. Overall, the Complement Navie Bayes classifier outperforms the Mulinomial Navie Bayes classifier in sentiment analysis, and I want to use it for the next challenge (combine category classification).\n",
    "|Complement Navie Bayes| Multionmial Navie Bayes|\n",
    "|----------------------|------------------------|\n",
    "|0.9084507042253521|0.8926056338028169|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f8a64d",
   "metadata": {},
   "source": [
    "### Task 2: Category Classification\n",
    "For category categorization (task 2), the combined characteristics of'review' and 'name' were chosen, purposefully eliminating only numerical properties such as'mean_checkin_time', 'ID', 'latitude', and 'longitude'. This strategic move aims to improve the performance of Bayes classifiers. By emphasizing the textual character of'review' and 'name', we improve the categorization process. These attributes give useful context and extra information about the categorization challenge. Using'review' and 'name' allows the classifier to identify complex patterns and semantics in the data, resulting in more accurate predictions. As a result, for predicting category classification in test.csv, using the combined characteristics of 'name' and'review' is regarded ideal for getting the best performance. This technique stresses the relevance of feature selection as well as using textual properties to increase classification algorithm efficacy.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "|name & review|name & numerical data | review & numerical data | all feature|\n",
    "|--------------|-----------------|---------------|------------|\n",
    "|0.9225352112676056| 0.6795774647887324|0.9084507042253521|0.9225352112676056|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e3e93ec-ddf8-411e-b0c7-c8b54e61c9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/vicmon/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/vicmon/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np;\n",
    "import re;\n",
    "import pandas as pd;\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer;\n",
    "from sklearn.model_selection import train_test_split;\n",
    "from sklearn.metrics import accuracy_score;\n",
    "from sklearn.naive_bayes import ComplementNB, MultinomialNB;\n",
    "from sklearn.metrics import accuracy_score;\n",
    "import nltk;\n",
    "nltk.download('stopwords');\n",
    "nltk.download('wordnet');\n",
    "from nltk.corpus import wordnet as wn;\n",
    "from nltk.stem import WordNetLemmatizer;\n",
    "from nltk.corpus import stopwords;\n",
    "from nltk.tokenize import word_tokenize;\n",
    "train_df = pd.read_csv(('train.csv'));\n",
    "test_df = pd.read_csv(('test.csv'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3309a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(sentences, vectorizer=None):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    processed_words = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        sentence = re.sub(r'[^a-zA-Z\\s]', '', sentence)\n",
    "        sentence = sentence.lower()\n",
    "        tokens = word_tokenize(sentence)\n",
    "        filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "        lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
    "        processed_word = ' '.join(lemmatized_tokens)\n",
    "        processed_words.append(processed_word)\n",
    "    \n",
    "    if vectorizer is None:\n",
    "        # vectorizer = TfidfVectorizer()\n",
    "        vectorizer = CountVectorizer()\n",
    "        X = vectorizer.fit_transform(processed_words)\n",
    "    else:\n",
    "        X = vectorizer.transform(processed_words)\n",
    "    \n",
    "    return X, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5528203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complement Navie Bayes classifcation Accuracy for task1: 0.9084507042253521\n",
      "Multinomia Navie Bayes classifcation Accuracy for task1: 0.8926056338028169\n"
     ]
    }
   ],
   "source": [
    "reviews = train_df.review\n",
    "y = train_df.category\n",
    "X,vectorizer = data_preprocessing(reviews)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "model = ComplementNB()\n",
    "model1 =MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Complement Navie Bayes classifcation Accuracy for task1:\", accuracy)\n",
    "\n",
    "\n",
    "model1 .fit(X_train, y_train)\n",
    "y_pred = model1.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Multinomia Navie Bayes classifcation Accuracy for task1:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c81a7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output for kaggle test\n",
    "\n",
    "# Extracting reviews from the 'test.csv' file\n",
    "review = test_df.review\n",
    "\n",
    "# preprocess all reviews from test.csv file\n",
    "X_test, _ = data_preprocessing(review, vectorizer)\n",
    "X = X_test\n",
    "\n",
    "# Making predictions for the reviews\n",
    "prediction = model.predict(X)\n",
    "\n",
    "#assigning ID with classified labels\n",
    "results_df = pd.DataFrame({'ID': test_df['ID'],'Category': prediction})\n",
    "\n",
    "# Write the DataFrame to a new CSV file\n",
    "results_df.to_csv('predictions_task1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a174e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for task2: 0.9225352112676056\n"
     ]
    }
   ],
   "source": [
    "\n",
    "labels = train_df.category\n",
    "#combine only review and name\n",
    "combine =  train_df['review'] +train_df['name'] #+ train_df['mean_checkin_time'].round().astype('str')\n",
    "X,vectorizer = data_preprocessing(combine)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
    "model = ComplementNB()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy for task2:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0152a0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for task2: 0.9225352112676056\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#All features\n",
    "combine =  train_df['review'] +train_df['name'] + train_df['mean_checkin_time'].round().astype('str') +train_df[\"latitude\"].astype('str') + train_df[\"longitude\"].astype('str') + train_df[\"ID\"].astype('str')\n",
    "X,vectorizer = data_preprocessing(combine)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
    "model = ComplementNB()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy for task2:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c75b927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for task2: 0.9084507042253521\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# review & numerical data\n",
    "combine =  train_df['review'] + train_df['mean_checkin_time'].round().astype('str') +train_df[\"latitude\"].astype('str') + train_df[\"longitude\"].astype('str') + train_df[\"ID\"].astype('str')\n",
    "X,vectorizer = data_preprocessing(combine)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
    "model = ComplementNB()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy for task2:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d5c38e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for task2: 0.6795774647887324\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# name & numerical data\n",
    "combine =  train_df['name'] + train_df['mean_checkin_time'].round().astype('str') +train_df[\"latitude\"].astype('str') + train_df[\"longitude\"].astype('str') + train_df[\"ID\"].astype('str')\n",
    "X,vectorizer = data_preprocessing(combine)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
    "model = ComplementNB()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy for task2:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba99c6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output for kaggle test\n",
    "combine =   test_df['name']+ test_df['review'] #+test_df['mean_checkin_time'].round().astype('str')\n",
    "X, _ = data_preprocessing(combine, vectorizer)\n",
    "\n",
    "prediction = model.predict(X)\n",
    "results_df = pd.DataFrame({'ID': test_df['ID'],'Category': prediction})\n",
    "\n",
    "# Write the DataFrame to a new CSV file\n",
    "results_df.to_csv('predictions_task2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

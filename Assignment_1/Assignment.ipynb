{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57fd3c9f",
   "metadata": {},
   "source": [
    "# UoA Copcsi 765 Assignemnt 1\n",
    "Shuo Mao 437681250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "673443c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "file_path = 'website-phishing.csv'\n",
    "web = pd.read_csv(file_path)\n",
    "\n",
    "bcp = pd.read_csv(\"BCP.csv\")\n",
    "arrhy = pd.read_csv(\"arrhythmia.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eb98fb19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>having_IP_Address</th>\n",
       "      <th>URL_Length</th>\n",
       "      <th>Shortining_Service</th>\n",
       "      <th>having_At_Symbol</th>\n",
       "      <th>double_slash_redirecting</th>\n",
       "      <th>Prefix_Suffix</th>\n",
       "      <th>having_Sub_Domain</th>\n",
       "      <th>SSLfinal_State</th>\n",
       "      <th>Domain_registeration_length</th>\n",
       "      <th>Favicon</th>\n",
       "      <th>...</th>\n",
       "      <th>popUpWidnow</th>\n",
       "      <th>Iframe</th>\n",
       "      <th>age_of_domain</th>\n",
       "      <th>DNSRecord</th>\n",
       "      <th>web_traffic</th>\n",
       "      <th>Page_Rank</th>\n",
       "      <th>Google_Index</th>\n",
       "      <th>Links_pointing_to_page</th>\n",
       "      <th>Statistical_report</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   having_IP_Address   URL_Length   Shortining_Service   having_At_Symbol  \\\n",
       "0                 -1            1                    1                  1   \n",
       "1                  1            1                    1                  1   \n",
       "2                  1            0                    1                  1   \n",
       "\n",
       "    double_slash_redirecting   Prefix_Suffix   having_Sub_Domain  \\\n",
       "0                         -1              -1                  -1   \n",
       "1                          1              -1                   0   \n",
       "2                          1              -1                  -1   \n",
       "\n",
       "    SSLfinal_State   Domain_registeration_length   Favicon  ...  \\\n",
       "0               -1                            -1         1  ...   \n",
       "1                1                            -1         1  ...   \n",
       "2               -1                            -1         1  ...   \n",
       "\n",
       "    popUpWidnow    Iframe   age_of_domain    DNSRecord     web_traffic   \\\n",
       "0              1        1               -1            -1             -1   \n",
       "1              1        1               -1            -1              0   \n",
       "2              1        1                1            -1              1   \n",
       "\n",
       "    Page_Rank   Google_Index   Links_pointing_to_page   Statistical_report  \\\n",
       "0          -1              1                        1                   -1   \n",
       "1          -1              1                        1                    1   \n",
       "2          -1              1                        0                   -1   \n",
       "\n",
       "     Class   \n",
       "0        -1  \n",
       "1        -1  \n",
       "2        -1  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e95a34a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample code number</th>\n",
       "      <th>Clump Thickness</th>\n",
       "      <th>Uniformity of Cell Size</th>\n",
       "      <th>Uniformity of Cell Shape</th>\n",
       "      <th>Marginal Adhesion</th>\n",
       "      <th>Single Epithelial Cell Size</th>\n",
       "      <th>Bare Nuclei</th>\n",
       "      <th>Bland Chromatin</th>\n",
       "      <th>Normal Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sample code number  Clump Thickness  Uniformity of Cell Size  \\\n",
       "0             1000025                5                        1   \n",
       "1             1002945                5                        4   \n",
       "2             1015425                3                        1   \n",
       "\n",
       "   Uniformity of Cell Shape  Marginal Adhesion  Single Epithelial Cell Size  \\\n",
       "0                         1                  1                            2   \n",
       "1                         4                  5                            7   \n",
       "2                         1                  1                            2   \n",
       "\n",
       "   Bare Nuclei  Bland Chromatin  Normal Nucleoli  Mitoses  Class  \n",
       "0            1                3                1        1      2  \n",
       "1           10                3                2        1      2  \n",
       "2            2                3                1        1      2  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcp.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7eff426d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>QRSduration</th>\n",
       "      <th>PRinterval</th>\n",
       "      <th>Q-Tinterval</th>\n",
       "      <th>Tinterval</th>\n",
       "      <th>Pinterval</th>\n",
       "      <th>QRS</th>\n",
       "      <th>...</th>\n",
       "      <th>chV6_QwaveAmp</th>\n",
       "      <th>chV6_RwaveAmp</th>\n",
       "      <th>chV6_SwaveAmp</th>\n",
       "      <th>chV6_RPwaveAmp</th>\n",
       "      <th>chV6_SPwaveAmp</th>\n",
       "      <th>chV6_PwaveAmp</th>\n",
       "      <th>chV6_TwaveAmp</th>\n",
       "      <th>chV6_QRSA</th>\n",
       "      <th>chV6_QRSTA</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>80</td>\n",
       "      <td>91</td>\n",
       "      <td>193</td>\n",
       "      <td>371</td>\n",
       "      <td>174</td>\n",
       "      <td>121</td>\n",
       "      <td>-16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.9</td>\n",
       "      <td>23.3</td>\n",
       "      <td>49.4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64</td>\n",
       "      <td>81</td>\n",
       "      <td>174</td>\n",
       "      <td>401</td>\n",
       "      <td>149</td>\n",
       "      <td>39</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>20.4</td>\n",
       "      <td>38.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>95</td>\n",
       "      <td>138</td>\n",
       "      <td>163</td>\n",
       "      <td>386</td>\n",
       "      <td>185</td>\n",
       "      <td>102</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>12.3</td>\n",
       "      <td>49.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 280 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age   sex   height   weight   QRSduration   PRinterval   Q-Tinterval  \\\n",
       "0   75     0      190       80            91          193           371   \n",
       "1   56     1      165       64            81          174           401   \n",
       "2   54     0      172       95           138          163           386   \n",
       "\n",
       "    Tinterval   Pinterval   QRS  ... chV6_QwaveAmp chV6_RwaveAmp  \\\n",
       "0         174         121   -16  ...           0.0           9.0   \n",
       "1         149          39    25  ...           0.0           8.5   \n",
       "2         185         102    96  ...           0.0           9.5   \n",
       "\n",
       "  chV6_SwaveAmp chV6_RPwaveAmp chV6_SPwaveAmp  chV6_PwaveAmp  chV6_TwaveAmp  \\\n",
       "0          -0.9            0.0            0.0            0.9            2.9   \n",
       "1           0.0            0.0            0.0            0.2            2.1   \n",
       "2          -2.4            0.0            0.0            0.3            3.4   \n",
       "\n",
       "   chV6_QRSA  chV6_QRSTA  class  \n",
       "0       23.3        49.4      8  \n",
       "1       20.4        38.8      6  \n",
       "2       12.3        49.0     10  \n",
       "\n",
       "[3 rows x 280 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrhy.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4669d7",
   "metadata": {},
   "source": [
    "By manually brife view the row data of each one, that I discover in the dataset of arrhythmia have missing value repersenting by question mark \"?\", thus I'll read through all data and replace `?` by `Null` value, so the machineism can process feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2fddd267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace '?' with np.nan for the entire DataFrame\n",
    "arrhy.replace('?', np.nan, inplace=True)\n",
    "# Convert all columns to numeric, errors='coerce' will convert errors (non-convertible values) to NaN\n",
    "data = arrhy.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Replace NaN values with the mean of their respective columns for the entire DataFrame\n",
    "data.fillna(data.mean(), inplace=True)\n",
    "#generate output csv file for following steps\n",
    "data.to_csv('new_arrhy.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde1e524",
   "metadata": {},
   "source": [
    "# 1: Decision Stump\n",
    "A decision stump is a decision tree with a depth of 1. It splits the dataset using the best feature based on a criterion like Gini impurity or information gain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "33e8a1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class DecisionStump:\n",
    "    def __init__(self):\n",
    "        # Initialize the decision stump with default values\n",
    "        self.threshold = None  # The value to decide if a data point goes left or right\n",
    "        self.feature_index = None  # The index of the feature to split on\n",
    "        self.left_value = None  # The most common class on the left side of the stump\n",
    "        self.right_value = None  # The most common class on the right side of the stump\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        best_info_gain = -1  # Initialize the best information gain to a value that will be updated\n",
    "        # Iterate over all features in the dataset\n",
    "        for feature_index in range(X.shape[1]): # in this case feature_index repersending columns in row dataset\n",
    "            thresholds = np.unique(X[:, feature_index])  # Get all unique values of the feature as potential thresholds\n",
    "            for threshold in thresholds:\n",
    "                # Calculate the information gain of splitting on this feature at this threshold\n",
    "                info_gain = self.information_gain(y, X[:, feature_index], threshold)\n",
    "                if info_gain > best_info_gain:\n",
    "                    # If this split provides a better information gain, update the stump's parameters\n",
    "                    best_info_gain = info_gain\n",
    "                    self.threshold = threshold\n",
    "                    self.feature_index = feature_index\n",
    "        \n",
    "        # After finding the best split, determine the output value (class) for each side of the split\n",
    "        # This uses the mean of the target values, which implicitly handles binary classification (0 and 1)\n",
    "        self.left_value = np.round(np.mean(y[X[:, self.feature_index] <= self.threshold]))\n",
    "        self.right_value = np.round(np.mean(y[X[:, self.feature_index] > self.threshold]))\n",
    "        \n",
    "        # Determine the value for the left and right child nodes\n",
    "        self.left_value = np.round(np.mean(y[X[:, self.feature_index] <= self.threshold]))\n",
    "        self.right_value = np.round(np.mean(y[X[:, self.feature_index] > self.threshold]))\n",
    "        \n",
    "    def predict(self, X):\n",
    "        # Generate predictions based on the threshold and feature index\n",
    "        predictions = np.where(X[:, self.feature_index] <= self.threshold, self.left_value, self.right_value)\n",
    "        return predictions\n",
    "\n",
    "    \n",
    "    def information_gain(self, y, feature_column, threshold):\n",
    "        parent_entropy = self.entropy(y)  # Calculate the entropy before the split\n",
    "        \n",
    "        # Create masks to split the data based on the threshold\n",
    "        left_child_index = feature_column <= threshold\n",
    "        right_child_index = feature_column > threshold\n",
    "        \n",
    "        # Ensure both sides of the split contain samples\n",
    "        if np.any(left_child_index) and np.any(right_child_index):\n",
    "            n = len(y)\n",
    "            n_left = np.sum(left_child_index)  # Number of samples in the left split\n",
    "            n_right = np.sum(right_child_index)  # Number of samples in the right split\n",
    "            # Weighted average of child entropies\n",
    "            child_entropy = (n_left / n) * self.entropy(y[left_child_index]) + (n_right / n) * self.entropy(y[right_child_index])\n",
    "            info_gain = parent_entropy - child_entropy  # Information gain is reduction in entropy\n",
    "            return info_gain\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    \n",
    "    def entropy(self, y):\n",
    "        if np.any(y < 0):  # Handle datasets where the negative class is labeled as -1\n",
    "            y = np.where(y == -1, 0, 1)\n",
    "        proportions = np.bincount(y) / len(y)\n",
    "        return -np.sum([p * np.log2(p) for p in proportions if p > 0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3853e4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the decision stump in website-phisihing dataset: 0.8960\n"
     ]
    }
   ],
   "source": [
    "# Assume the dataset has been loaded into a DataFrame named data\n",
    "# and the necessary preprocessing has been done.\n",
    "# Splitting the dataset into features (X) and target (y)\n",
    "stump = DecisionStump()\n",
    "\n",
    "\n",
    "X = web.iloc[:, :-1].values# Selecting all expect y(class)\n",
    "y = web.iloc[:, -1].values# Selecting Class\n",
    "\n",
    "# train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=43)\n",
    "\n",
    "\n",
    "#fit the decision stump\n",
    "\n",
    "stump.fit(X_train, y_train)\n",
    "\n",
    "# Use the stump to make predictions\n",
    "predictions = stump.predict(X_test)\n",
    "# Optionally, evaluate the stump's performance\n",
    "accuracy = np.mean(predictions == y_test)\n",
    "\n",
    "print(f'Accuracy of the decision stump in website-phisihing dataset: {accuracy:.4f}')\n",
    "\n",
    "web_DS = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bdadf803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the decision stump in BCP dataset: 0.8978\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = bcp.iloc[:, :-1].values\n",
    "y = bcp.iloc[:, -1].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=78)\n",
    "stump.fit(X_train, y_train)\n",
    "# Use the stump to make predictions\n",
    "predictions = stump.predict(X_test)\n",
    "# Optionally, evaluate the stump's performance\n",
    "accuracy = np.mean(predictions == y_test)\n",
    "\n",
    "print(f'Accuracy of the decision stump in BCP dataset: {accuracy:.4f}')\n",
    "\n",
    "bcp_DS  = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a50b85c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the decision stump in arrhythmia dataset: 0.0220\n"
     ]
    }
   ],
   "source": [
    "arrhy_aft = pd.read_csv(\"new_arrhy.csv\")\n",
    "\n",
    "X= arrhy_aft.iloc[:,:-1].values\n",
    "y = arrhy_aft.iloc[:,-1].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "stump.fit(X_train, y_train)\n",
    "# Use the stump to make predictions\n",
    "predictions = stump.predict(X_test)\n",
    "# Optionally, evaluate the stump's performance\n",
    "accuracy = np.mean(predictions == y_test)\n",
    "\n",
    "print(f'Accuracy of the decision stump in arrhythmia dataset: {accuracy:.4f}')\n",
    "arrh_DS  = accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc00888",
   "metadata": {},
   "source": [
    "After applying the Decision Stump method to each raw dataset, it was discovered that the Decision Stump works effectively for basic binary classification tasks. For example, in the website-phishing dataset, which has just two possible outcomes `(-1, 1)`, and the BCP dataset `(with outcomes 2,4)`, the accuracy rates were pretty high, about `0.89`.This highlights the effectiveness of Decision Stumps in binary classification scenarios. In contrast, the Decision Stump performs substantially worse in non-binary classification cases, such as the arrhythmia dataset, which has `13` alternative outcomes. In this example, the accuracy dropped to a meager `0.022`, indicating a `2%` probability of making a right forecast. This striking disparity demonstrates Decision Stumps' limits in handling increasingly complicated, non-binary categorization tasks.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a52d5a",
   "metadata": {},
   "source": [
    "# 2: Unpruned Decision Tree\n",
    "An unpruned decision tree grows until all leaves are pure or until every leaf contains a minimum number of samples. Here, you recursively split the nodes based on the best split criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f32fd086",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, info_gain=None, value=None):\n",
    "        # Node class to store information about each point in the decision tree.\n",
    "        self.feature_index = feature_index  # Index of the feature used for splitting\n",
    "        self.threshold = threshold  # Threshold value for the split at this node\n",
    "        self.left = left  # Reference to the left child node\n",
    "        self.right = right  # Reference to the right child node\n",
    "        self.info_gain = info_gain  # Information gain from the split at this node\n",
    "        self.value = value  # The class value if this is a leaf node, else None\n",
    "\n",
    "\n",
    "\n",
    "class DecisionTreeClassifier():\n",
    "    def __init__(self, min_samples_split=2, max_depth=2):\n",
    "        # Initialize the decision tree classifier with stopping conditions.\n",
    "        self.root = None  # Root node of the tree, initially None\n",
    "        self.min_samples_split = min_samples_split  # Minimum number of samples required to split a node\n",
    "        self.max_depth = max_depth  # Maximum depth of the tree\n",
    "\n",
    "        \n",
    "    def build_tree(self, dataset, curr_depth=0):\n",
    "        # Recursively builds the decision tree from the given dataset.\n",
    "        X, Y = dataset[:,:-1], dataset[:,-1]  # Split dataset into features (X) and target (Y)\n",
    "        num_samples, num_features = np.shape(X)\n",
    "        \n",
    "        # Base case: stop splitting if minimum samples or maximum depth criteria are met\n",
    "        if num_samples >= self.min_samples_split and curr_depth <= self.max_depth:\n",
    "            best_split = self.get_best_split(dataset, num_samples, num_features)\n",
    "            if best_split[\"info_gain\"] > 0:  # Ensure positive information gain for splitting\n",
    "                # Recursively build left and right subtrees\n",
    "                left_subtree = self.build_tree(best_split[\"dataset_left\"], curr_depth+1)\n",
    "                right_subtree = self.build_tree(best_split[\"dataset_right\"], curr_depth+1)\n",
    "                return Node(best_split[\"feature_index\"], best_split[\"threshold\"], left_subtree, right_subtree, best_split[\"info_gain\"])\n",
    "        \n",
    "        return Node(value=self.calculate_leaf_value(Y))  # Leaf node with class prediction\n",
    "\n",
    "    \n",
    "    def get_best_split(self, dataset, num_samples, num_features):\n",
    "        \"\"\" This method identifies the optimal feature and threshold for splitting the dataset into two child nodes. It aims to maximize the information gain from the split.\"\"\"\n",
    "        # Initialize the dictionary to store the best split found during the process\n",
    "        best_split = {}\n",
    "        # Initialize the maximum information gain to a very low number\n",
    "        max_info_gain = -float(\"inf\")\n",
    "         # Iterate over all features in the dataset\n",
    "        for feature_index in range(num_features):\n",
    "            # Extract all values for the current feature\n",
    "            feature_values = dataset[:, feature_index]\n",
    "            # Identify all unique values of the feature to consider as potential thresholds\n",
    "            possible_thresholds = np.unique(feature_values)\n",
    "             # Test each threshold to find the best split for the current feature\n",
    "            for threshold in possible_thresholds:\n",
    "                # Split the dataset into two parts: one part where the feature values are less than or equal to the threshold\n",
    "                 # and another part where the feature values are greater than the threshold\n",
    "                dataset_left, dataset_right = self.split(dataset, feature_index, threshold)\n",
    "                # Ensure both left and right splits contain data\n",
    "                if len(dataset_left) > 0 and len(dataset_right) > 0:\n",
    "                    # Extract the target values for the whole dataset, and each of the splits\n",
    "                    y, left_y, right_y = dataset[:, -1], dataset_left[:, -1], dataset_right[:, -1]\n",
    "                    # Calculate the information gain achieved by the current split\n",
    "                    curr_info_gain = self.information_gain(y, left_y, right_y, \"gini\")\n",
    "                    # If the information gain from the current split is higher than the maximum found so far,\n",
    "                    # update the best split to this split\n",
    "                    if curr_info_gain > max_info_gain:\n",
    "                        best_split[\"feature_index\"] = feature_index\n",
    "                        best_split[\"threshold\"] = threshold\n",
    "                        best_split[\"dataset_left\"] = dataset_left\n",
    "                        best_split[\"dataset_right\"] = dataset_right\n",
    "                        best_split[\"info_gain\"] = curr_info_gain\n",
    "                        max_info_gain = curr_info_gain\n",
    "        return best_split\n",
    "\n",
    "    \n",
    "    def split(self, dataset, feature_index, threshold):\n",
    "        # Creates an empty array for the left dataset. This will hold all rows\n",
    "        # where the value in the specified feature column is less than or equal\n",
    "        # to the threshold.\n",
    "        dataset_left = np.array([row for row in dataset if row[feature_index] <= threshold]) \n",
    "        # Similarly, creates an empty array for the right dataset. This will\n",
    "        # contain all rows where the value in the specified feature column is\n",
    "        # greater than the threshold.\n",
    "        dataset_right = np.array([row for row in dataset if row[feature_index] > threshold])\n",
    "        # Returns the two subsets. These will be used as the new datasets for\n",
    "        # the subsequent recursive calls to build the left and right subtrees,\n",
    "        # respectively.\n",
    "        return dataset_left, dataset_right\n",
    "\n",
    "\n",
    "    def information_gain(self, parent, l_child, r_child, mode=\"entropy\"):  \n",
    "        # Calculate the proportion of samples that go to the left and right child nodes.\n",
    "        weight_l = len(l_child) / len(parent)\n",
    "        weight_r = len(r_child) / len(parent)\n",
    "        # If the mode is set to \"gini\", use the Gini impurity measure to calculate information gain.\n",
    "        if mode == \"gini\":\n",
    "            # Information gain is the impurity of the parent node minus the weighted sum of the impurity\n",
    "            # of the left and right child nodes.\n",
    "            gain = self.gini_index(parent) - (weight_l * self.gini_index(l_child) + weight_r * self.gini_index(r_child))\n",
    "        else:\n",
    "            # If the mode is not \"gini\" (default is \"entropy\"), use the entropy measure to calculate information gain.\n",
    "            gain = self.entropy(parent) - (weight_l * self.entropy(l_child) + weight_r * self.entropy(r_child))\n",
    "        \n",
    "        return gain\n",
    "\n",
    "    \n",
    "    def entropy(self, y):\n",
    "        # Identify the unique class labels in the dataset.\n",
    "        class_labels = np.unique(y)\n",
    "        # Initialize entropy to zero. Entropy will accumulate the disorder measure for each class.\n",
    "        entropy = 0\n",
    "        # Iterate over each class label. \n",
    "        for cls in class_labels:\n",
    "            # Calculate the proportion (p_cls) of instances in the dataset belonging to the current class.\n",
    "            p_cls = len(y[y == cls]) / len(y)\n",
    "            # Update the entropy using the entropy formula part associated with this class.\n",
    "            # The formula for entropy of a class is: -p * log2(p), where p is the class proportion.\n",
    "            entropy += -p_cls * np.log2(p_cls)\n",
    "        # Return the total entropy, which represents the disorder within the entire dataset.\n",
    "        return entropy\n",
    "\n",
    "    \n",
    "    def gini_index(self, y):      \n",
    "        # Identify the unique class labels in the dataset.\n",
    "        class_labels = np.unique(y)\n",
    "        # Initialize gini to zero. This will accumulate the squared proportion of each class.\n",
    "        gini = 0\n",
    "        # Iterate over each class label.\n",
    "        for cls in class_labels:\n",
    "            # Calculate the proportion (p_cls) of instances in the dataset belonging to the current class.\n",
    "            p_cls = len(y[y == cls]) / len(y)\n",
    "            # Accumulate the square of the proportion of the current class to the gini score.\n",
    "            gini += p_cls**2\n",
    "        # Gini impurity is calculated as 1 minus the accumulated score.\n",
    "        # This transformation ensures that a higher value indicates higher impurity.\n",
    "        return 1 - gini\n",
    "\n",
    "        \n",
    "    def calculate_leaf_value(self, Y):\n",
    "        # Convert Y to a list if it's not already one. This ensures compatibility with the 'max' function and 'count' method.\n",
    "        Y = list(Y)\n",
    "        # Use the 'max' function with a key that counts the occurrences of each class label in Y.\n",
    "        # This returns the class label that appears most frequently in Y.\n",
    "        return max(Y, key=Y.count)\n",
    "\n",
    "    \n",
    "    def print_tree(self, tree=None, indent=\" \"):\n",
    "        ''' function to print the tree '''     \n",
    "        if not tree:\n",
    "            tree = self.root\n",
    "        if tree.value is not None:\n",
    "            print(tree.value)\n",
    "        else:\n",
    "            print(\"X_\"+str(tree.feature_index), \"<=\", tree.threshold, \"?\", tree.info_gain)\n",
    "            print(\"%sleft:\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.left, indent + indent)\n",
    "            print(\"%sright:\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.right, indent + indent)\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        # Ensures that Y is in the correct shape.\n",
    "        # If Y is a 1-dimensional array (a common format for labels), it reshapes it to a 2-dimensional array with a single column.\n",
    "        # This uniform shape is necessary for concatenating Y with X.\n",
    "        if Y.ndim == 1:\n",
    "            Y = Y.reshape(-1, 1)\n",
    "        # This combined dataset format is convenient for the subsequent operations of splitting and building the tree.\n",
    "        dataset = np.concatenate((X, Y), axis=1)\n",
    "        # Initiates the recursive process of building the decision tree.\n",
    "        # The build_tree method will be called with the entire dataset,\n",
    "        # and it will recursively split the dataset on the best features and thresholds,\n",
    "        # until it meets the stopping criteria to create leaf nodes.\n",
    "        self.root = self.build_tree(dataset)\n",
    "\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # This line iterates over each example in the dataset X. For each example (x),\n",
    "        # it calls the make_prediction method, starting from the root of the tree.\n",
    "        # The result is a list of predictions corresponding to each example in X.\n",
    "        predictions = [self.make_prediction(x, self.root) for x in X]\n",
    "        return predictions\n",
    "\n",
    "    \n",
    "    def make_prediction(self, x, tree):\n",
    "        # Checks if the current node (tree) is a leaf node by verifying if it has a non-None value.\n",
    "        # Leaf nodes in a decision tree do not have further splits and contain a class value (prediction).\n",
    "        if tree.value is not None:\n",
    "            return tree.value  # If it's a leaf node, return the value (class label) of the leaf node.\n",
    "        # Retrieves the feature value from the instance x for the feature at index tree.feature_index.\n",
    "        # This value is used to decide whether to move left or right down the tree.\n",
    "        feature_val = x[tree.feature_index]\n",
    "        # If the feature value is less than or equal to the threshold of the current node,\n",
    "        # the method recursively calls itself to move to the left child of the current node.\n",
    "        if feature_val <= tree.threshold:\n",
    "            return self.make_prediction(x, tree.left)\n",
    "        else:\n",
    "            # If the feature value is greater than the threshold of the current node,\n",
    "            # the method recursively calls itself to move to the right child of the current node.\n",
    "            return self.make_prediction(x, tree.right)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c76e0aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading website-phishing \n",
    "file_path = 'website-phishing.csv'\n",
    "data = pd.read_csv(file_path, skiprows=1, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b0975806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9249208502939846\n"
     ]
    }
   ],
   "source": [
    "#re-assigning data value to web-phishing\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values.reshape(-1, 1)  # Ensure Y is correctly reshaped\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=41)\n",
    "\n",
    "# Your classifier's fit and predict methods should work as intended if implemented correctly\n",
    "classifier = DecisionTreeClassifier(min_samples_split=2, max_depth=5)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test) \n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "web_dt  = accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a090ac4",
   "metadata": {},
   "source": [
    "In this investigation, I used `min_samples_split = 2` for our classification issue, which corresponds to the binary character of our results (true or false). This setting is often beneficial in such situations. For `max_depth`, I chose a depth of 5. The objective for this decision is to create a balance between model complexity and computing efficiency while avoiding overfitting. A tree that is overly deep may result in overfitting, which occurs when the model learns noise from the training data rather than the real signal, as well as considerably increasing computation time. In contrast, a shallow tree, while quicker, may not capture the underlying patterns well, resulting in underfitting.\n",
    "\n",
    "I ran tests with `max_depth` values of 2, 5, 8, and 12. A depth of two was insufficient to capture the intricacies of the data. While a depth of 8 produced more accurate results, the longer calculating time was a considerable disadvantage. A depth of 12 resulted in overfitting concerns, indicating that the model was too complicated for our data. Thus, a depth of 5 emerged as the best option, giving a reasonable balance of model accuracy and efficiency, ensuring the model is sophisticated enough to discover meaningful patterns without spending too much time on computations or fitting to noise.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "37354102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_7 <= 0 ? 0.2957943189016128\n",
      " left:X_13 <= -1 ? 0.04430056122522666\n",
      "  left:-1\n",
      "  right:X_14 <= -1 ? 0.06460174188584966\n",
      "    left:X_5 <= -1 ? 0.03600565361530961\n",
      "        left:X_25 <= 0 ? 0.004079756680114899\n",
      "                left:X_26 <= -1 ? 0.004227856189806201\n",
      "                                left:-1\n",
      "                                right:-1\n",
      "                right:X_27 <= -1 ? 0.013200203001968669\n",
      "                                left:-1\n",
      "                                right:-1\n",
      "        right:1\n",
      "    right:X_8 <= -1 ? 0.0697549763254604\n",
      "        left:X_5 <= -1 ? 0.048180652363138676\n",
      "                left:X_27 <= -1 ? 0.046886240984504945\n",
      "                                left:-1\n",
      "                                right:1\n",
      "                right:1\n",
      "        right:X_5 <= -1 ? 0.021731666913208436\n",
      "                left:X_27 <= -1 ? 0.01651908213159048\n",
      "                                left:-1\n",
      "                                right:-1\n",
      "                right:1\n",
      " right:X_13 <= -1 ? 0.04845618966120577\n",
      "  left:X_5 <= -1 ? 0.10458852646620756\n",
      "    left:X_28 <= -1 ? 0.06423943998035152\n",
      "        left:X_0 <= -1 ? 0.2975206611570247\n",
      "                left:-1\n",
      "                right:1\n",
      "        right:X_10 <= -1 ? 0.01912070759625383\n",
      "                left:X_8 <= -1 ? 0.1701388888888889\n",
      "                                left:1\n",
      "                                right:-1\n",
      "                right:-1\n",
      "    right:1\n",
      "  right:X_25 <= 0 ? 0.00779061632776068\n",
      "    left:X_25 <= -1 ? 0.04074313660153711\n",
      "        left:X_4 <= -1 ? 0.000797954203885759\n",
      "                left:X_2 <= -1 ? 0.05680858678390986\n",
      "                                left:1\n",
      "                                right:-1\n",
      "                right:X_14 <= -1 ? 0.0003658695499781234\n",
      "                                left:1\n",
      "                                right:1\n",
      "        right:X_13 <= 0 ? 0.046226292653399226\n",
      "                left:X_6 <= 0 ? 0.05973654350400709\n",
      "                                left:-1\n",
      "                                right:1\n",
      "                right:1\n",
      "    right:X_14 <= -1 ? 0.0029262282113992205\n",
      "        left:X_15 <= -1 ? 0.009749757383859803\n",
      "                left:X_6 <= 0 ? 0.01820295060256999\n",
      "                                left:1\n",
      "                                right:1\n",
      "                right:X_12 <= -1 ? 8.298802534670562e-05\n",
      "                                left:1\n",
      "                                right:1\n",
      "        right:X_0 <= -1 ? 0.0003174138011578509\n",
      "                left:X_28 <= 0 ? 0.002007557831563603\n",
      "                                left:1\n",
      "                                right:1\n",
      "                right:X_13 <= 0 ? 4.5058945180521254e-05\n",
      "                                left:1\n",
      "                                right:1\n"
     ]
    }
   ],
   "source": [
    "#Ploting tree structure of web data\n",
    "classifier.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b80956d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading BCP\n",
    "file_path = 'BCP.csv'\n",
    "data = pd.read_csv(file_path, skiprows=1, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f58c90c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9197080291970803\n"
     ]
    }
   ],
   "source": [
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values.reshape(-1, 1)  # Ensure Y is correctly reshaped\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=41)\n",
    "\n",
    "# Your classifier's fit and predict methods should work as intended if implemented correctly\n",
    "classifier = DecisionTreeClassifier(min_samples_split=2, max_depth=5)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test) \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "bcp_dt  = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5b65b19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_2 <= 2 ? 0.3487699066940749\n",
      " left:X_1 <= 6 ? 0.025447176988002626\n",
      "  left:X_6 <= 4 ? 0.008622488956713158\n",
      "    left:2\n",
      "    right:X_1 <= 3 ? 0.3173553719008265\n",
      "        left:2\n",
      "        right:X_4 <= 4 ? 0.31999999999999984\n",
      "                left:4\n",
      "                right:2\n",
      "  right:X_6 <= 1 ? 0.20833333333333334\n",
      "    left:X_3 <= 2 ? 0.4444444444444444\n",
      "        left:2\n",
      "        right:4\n",
      "    right:4\n",
      " right:X_3 <= 2 ? 0.0798383566669814\n",
      "  left:X_1 <= 5 ? 0.3046875\n",
      "    left:2\n",
      "    right:4\n",
      "  right:X_2 <= 4 ? 0.011560234225791152\n",
      "    left:X_6 <= 3 ? 0.10528573584254902\n",
      "        left:X_4 <= 3 ? 0.2268518518518518\n",
      "                left:X_7 <= 3 ? 0.19753086419753085\n",
      "                                left:2\n",
      "                                right:4\n",
      "                right:4\n",
      "        right:X_5 <= 5 ? 0.016326530612244913\n",
      "                left:4\n",
      "                right:X_0 <= 1002945 ? 0.1866666666666665\n",
      "                                left:2\n",
      "                                right:4\n",
      "    right:X_0 <= 242970 ? 0.002417433649135034\n",
      "        left:X_0 <= 160296 ? 0.31999999999999984\n",
      "                left:4\n",
      "                right:2\n",
      "        right:X_0 <= 1286943 ? 0.0005979938271603556\n",
      "                left:4\n",
      "                right:X_0 <= 1293439 ? 0.09500000000000008\n",
      "                                left:2\n",
      "                                right:4\n"
     ]
    }
   ],
   "source": [
    "# ploting tree \n",
    "classifier.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "725c544f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading arrhythmia\n",
    "file_path = 'new_arrhy.csv'#Notice do not loading original dataset program will crash\n",
    "data = pd.read_csv(file_path, skiprows=1, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5f4200db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6703296703296703\n"
     ]
    }
   ],
   "source": [
    "#Should expect improve than decision stump\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values.reshape(-1, 1)  # Ensure Y is correctly reshaped\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=41)\n",
    "\n",
    "# Your classifier's fit and predict methods should work as intended if implemented correctly\n",
    "classifier = DecisionTreeClassifier(min_samples_split=2, max_depth=5)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test) \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "arrh_dt  = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8d22b392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_223 <= 0.9 ? 0.06665457176492173\n",
      " left:X_276 <= 0.3 ? 0.060918986699485034\n",
      "  left:X_256 <= -0.5 ? 0.15560044954165708\n",
      "    left:X_5 <= 118.0 ? 0.11819021237303784\n",
      "        left:X_0 <= 17.0 ? 0.4444444444444444\n",
      "                left:2.0\n",
      "                right:1.0\n",
      "        right:2.0\n",
      "    right:X_4 <= 121.0 ? 0.13284499054820398\n",
      "        left:X_75 <= 24.0 ? 0.14222962382445148\n",
      "                left:X_111 <= 0.0 ? 0.15143876337693218\n",
      "                                left:1.0\n",
      "                                right:3.0\n",
      "                right:X_137 <= 32.0 ? 0.26446280991735543\n",
      "                                left:15.0\n",
      "                                right:4.0\n",
      "        right:9.0\n",
      "  right:X_14 <= 58.0 ? 0.06625289953896918\n",
      "    left:X_265 <= 0.6 ? 0.1953816237238697\n",
      "        left:X_255 <= 0.3 ? 0.15570934256055358\n",
      "                left:X_0 <= 27.0 ? 0.5\n",
      "                                left:16.0\n",
      "                                right:10.0\n",
      "                right:6.0\n",
      "        right:X_1 <= 0.0 ? 0.31999999999999984\n",
      "                left:1.0\n",
      "                right:6.0\n",
      "    right:X_111 <= 20.0 ? 0.05696896771348364\n",
      "        left:X_14 <= 101.0 ? 0.04347961231510966\n",
      "                left:X_236 <= -1.0 ? 0.04442637172041847\n",
      "                                left:10.0\n",
      "                                right:1.0\n",
      "                right:5.0\n",
      "        right:X_166 <= 0.6 ? 0.20888888888888912\n",
      "                left:X_6 <= 401.0 ? 0.23999999999999985\n",
      "                                left:3.0\n",
      "                                right:2.0\n",
      "                right:X_2 <= 169.0 ? 0.31999999999999995\n",
      "                                left:5.0\n",
      "                                right:16.0\n",
      " right:X_12 <= 75.0 ? 0.09766951942067148\n",
      "  left:X_237 <= -26.5 ? 0.10078786977850446\n",
      "    left:X_0 <= 35.0 ? 0.3333333333333334\n",
      "        left:6.0\n",
      "        right:X_0 <= 44.0 ? 0.5\n",
      "                left:1.0\n",
      "                right:2.0\n",
      "    right:X_112 <= 56.0 ? 0.06386999244142086\n",
      "        left:X_182 <= -5.0 ? 0.07133058984910856\n",
      "                left:1.0\n",
      "                right:10.0\n",
      "        right:1.0\n",
      "  right:X_0 <= 1.0 ? 0.25\n",
      "    left:5.0\n",
      "    right:X_0 <= 8.0 ? 0.3333333333333334\n",
      "        left:16.0\n",
      "        right:X_0 <= 34.0 ? 0.5\n",
      "                left:14.0\n",
      "                right:15.0\n"
     ]
    }
   ],
   "source": [
    "# Plotting tree\n",
    "classifier.print_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179fe57e",
   "metadata": {},
   "source": [
    "\"After implementing the Decision Tree algorithm on each row of data, observations indicate a distinct performance pattern across different types of classification tasks. In simple binary classification scenarios, the improvement in performance is marginal. However, a significant enhancement is observed in non-binary classification tasks, where the accuracy rate dramatically increased from `0.022` to `0.670`. This improvement aligns with expectations, highlighting the Decision Tree's capability to handle complex classification problems with multiple classes more effectively than simpler, binary classification tasks.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c075754",
   "metadata": {},
   "source": [
    "# 3: Pruned Decision Tree\n",
    "Pruning can be done using several strategies like reduced error pruning (post-pruning) or setting a maximum depth (pre-pruning). In a Jupyter notebook, you can extend the unpruned decision tree with pruning capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d3789056",
   "metadata": {},
   "outputs": [],
   "source": [
    " # cross vaildation and return best performance one\n",
    "def puring(X_temp, y_temp):\n",
    "        #define defalut values\n",
    "        default_max_depth = 9\n",
    "        # key-value storing both depth and outcome\n",
    "        records = {}\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=41)\n",
    "        # # Define the K-Fold cross-validator\n",
    "        # kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "        # iterater through \n",
    "        for i in range(1, default_max_depth ):\n",
    "            model1 = DecisionTreeClassifier(min_samples_split=2, max_depth=i)\n",
    "            model1.fit(X_train, y_train)\n",
    "            y_pred = model1.predict(X_val)\n",
    "            accuracy = accuracy_score(y_val, y_pred)\n",
    "            records[i] = accuracy\n",
    "            # print(\"depth:\", i, \"accuracy:\", accuracy)\n",
    "        best_record = max(records, key=records.get)\n",
    "        print(\"picking best depth: \", best_record, \"with accuracy \", records[best_record])    \n",
    "        return  best_record"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3567722",
   "metadata": {},
   "source": [
    "## Purning method : \n",
    "In my pruning method, I go through all conceivable tree depths from 1 to 8. The model is trained at each depth, and its performance is analyzed to determine the ideal depth for the best outcomes. This ideal depth is then utilized to fit the final model, ensuring that the tree is neither too shallow (possibly underfitting) nor too deep (to avoid overfitting), resulting in a balance between model complexity and predictive performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6411c12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "picking best depth:  7 with accuracy  0.9493441881501583\n",
      "Accuracy: 0.937584803256445\n"
     ]
    }
   ],
   "source": [
    "file_path = 'website-phishing.csv'\n",
    "data = pd.read_csv(file_path, skiprows=1, header=None)\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values.reshape(-1, 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=41)\n",
    "\n",
    "# Your classifier's fit and predict methods should work as intended if implemented correctly\n",
    "\n",
    "classifier = DecisionTreeClassifier(min_samples_split=2, max_depth=puring(X_train, y_train))\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test) \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "web_dt_p  = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0cf19287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_7 <= 0 ? 0.2957943189016128\n",
      " left:X_13 <= -1 ? 0.04430056122522666\n",
      "  left:-1\n",
      "  right:X_14 <= -1 ? 0.06460174188584966\n",
      "    left:X_5 <= -1 ? 0.03600565361530961\n",
      "        left:X_25 <= 0 ? 0.004079756680114899\n",
      "                left:X_26 <= -1 ? 0.004227856189806201\n",
      "                                left:X_24 <= -1 ? 0.012094317385524134\n",
      "                                                                left:-1\n",
      "                                                                right:X_11 <= -1 ? 0.02499504066653435\n",
      "                                                                                                                                left:1\n",
      "                                                                                                                                right:-1\n",
      "                                right:X_19 <= -1 ? 0.0038422776518014096\n",
      "                                                                left:X_0 <= -1 ? 0.375\n",
      "                                                                                                                                left:-1\n",
      "                                                                                                                                right:1\n",
      "                                                                right:-1\n",
      "                right:X_27 <= -1 ? 0.013200203001968669\n",
      "                                left:-1\n",
      "                                right:X_1 <= 0 ? 0.014945454413754389\n",
      "                                                                left:X_8 <= -1 ? 0.011369005400603871\n",
      "                                                                                                                                left:-1\n",
      "                                                                                                                                right:-1\n",
      "                                                                right:X_9 <= -1 ? 0.40816326530612246\n",
      "                                                                                                                                left:1\n",
      "                                                                                                                                right:-1\n",
      "        right:1\n",
      "    right:X_8 <= -1 ? 0.0697549763254604\n",
      "        left:X_5 <= -1 ? 0.048180652363138676\n",
      "                left:X_27 <= -1 ? 0.046886240984504945\n",
      "                                left:X_11 <= -1 ? 0.2335170668483185\n",
      "                                                                left:X_14 <= 0 ? 0.11932938856015768\n",
      "                                                                                                                                left:1\n",
      "                                                                                                                                right:-1\n",
      "                                                                right:X_0 <= -1 ? 0.007750472589792154\n",
      "                                                                                                                                left:-1\n",
      "                                                                                                                                right:-1\n",
      "                                right:X_25 <= 0 ? 0.047962240712607906\n",
      "                                                                left:X_6 <= 0 ? 0.11726120033812337\n",
      "                                                                                                                                left:-1\n",
      "                                                                                                                                right:1\n",
      "                                                                right:X_13 <= 0 ? 0.027357829129688316\n",
      "                                                                                                                                left:1\n",
      "                                                                                                                                right:1\n",
      "                right:1\n",
      "        right:X_5 <= -1 ? 0.021731666913208436\n",
      "                left:X_27 <= -1 ? 0.01651908213159048\n",
      "                                left:X_12 <= -1 ? 0.014299516908212434\n",
      "                                                                left:-1\n",
      "                                                                right:X_28 <= 0 ? 0.04653191798749462\n",
      "                                                                                                                                left:-1\n",
      "                                                                                                                                right:-1\n",
      "                                right:X_15 <= 0 ? 0.01598401316145298\n",
      "                                                                left:X_7 <= -1 ? 0.011636942318810017\n",
      "                                                                                                                                left:-1\n",
      "                                                                                                                                right:-1\n",
      "                                                                right:X_12 <= -1 ? 0.34027777777777773\n",
      "                                                                                                                                left:-1\n",
      "                                                                                                                                right:1\n",
      "                right:1\n",
      " right:X_13 <= -1 ? 0.04845618966120577\n",
      "  left:X_5 <= -1 ? 0.10458852646620756\n",
      "    left:X_28 <= -1 ? 0.06423943998035152\n",
      "        left:X_0 <= -1 ? 0.2975206611570247\n",
      "                left:-1\n",
      "                right:1\n",
      "        right:X_10 <= -1 ? 0.01912070759625383\n",
      "                left:X_8 <= -1 ? 0.1701388888888889\n",
      "                                left:X_19 <= -1 ? 0.34027777777777773\n",
      "                                                                left:X_12 <= -1 ? 0.21875\n",
      "                                                                                                                                left:-1\n",
      "                                                                                                                                right:1\n",
      "                                                                right:-1\n",
      "                                right:-1\n",
      "                right:-1\n",
      "    right:1\n",
      "  right:X_25 <= 0 ? 0.00779061632776068\n",
      "    left:X_25 <= -1 ? 0.04074313660153711\n",
      "        left:X_4 <= -1 ? 0.000797954203885759\n",
      "                left:X_2 <= -1 ? 0.05680858678390986\n",
      "                                left:X_20 <= -1 ? 0.02666179693206705\n",
      "                                                                left:-1\n",
      "                                                                right:1\n",
      "                                right:X_12 <= -1 ? 0.49382716049382713\n",
      "                                                                left:-1\n",
      "                                                                right:1\n",
      "                right:X_14 <= -1 ? 0.0003658695499781234\n",
      "                                left:X_16 <= -1 ? 0.0014111928499560972\n",
      "                                                                left:1\n",
      "                                                                right:X_29 <= -1 ? 0.008902197937881273\n",
      "                                                                                                                                left:-1\n",
      "                                                                                                                                right:1\n",
      "                                right:X_6 <= 0 ? 1.8715908343853137e-05\n",
      "                                                                left:X_0 <= -1 ? 0.0002372997920331056\n",
      "                                                                                                                                left:1\n",
      "                                                                                                                                right:1\n",
      "                                                                right:1\n",
      "        right:X_13 <= 0 ? 0.046226292653399226\n",
      "                left:X_6 <= 0 ? 0.05973654350400709\n",
      "                                left:X_5 <= -1 ? 0.05022871633193965\n",
      "                                                                left:X_20 <= -1 ? 0.015577470618836464\n",
      "                                                                                                                                left:1\n",
      "                                                                                                                                right:-1\n",
      "                                                                right:1\n",
      "                                right:X_24 <= -1 ? 0.015092647718117358\n",
      "                                                                left:X_28 <= 0 ? 0.04573902288188003\n",
      "                                                                                                                                left:-1\n",
      "                                                                                                                                right:1\n",
      "                                                                right:X_15 <= -1 ? 0.02061538189010459\n",
      "                                                                                                                                left:1\n",
      "                                                                                                                                right:1\n",
      "                right:1\n",
      "    right:X_14 <= -1 ? 0.0029262282113992205\n",
      "        left:X_15 <= -1 ? 0.009749757383859803\n",
      "                left:X_6 <= 0 ? 0.01820295060256999\n",
      "                                left:X_28 <= 0 ? 0.06196420395891905\n",
      "                                                                left:X_16 <= -1 ? 0.04735296876983275\n",
      "                                                                                                                                left:1\n",
      "                                                                                                                                right:-1\n",
      "                                                                right:X_24 <= -1 ? 0.01593615011515509\n",
      "                                                                                                                                left:1\n",
      "                                                                                                                                right:1\n",
      "                                right:X_12 <= -1 ? 0.0017922592884985766\n",
      "                                                                left:X_21 <= -1 ? 0.01224044740945704\n",
      "                                                                                                                                left:1\n",
      "                                                                                                                                right:1\n",
      "                                                                right:X_23 <= -1 ? 0.0013667722981448582\n",
      "                                                                                                                                left:1\n",
      "                                                                                                                                right:1\n",
      "                right:X_12 <= -1 ? 8.298802534670562e-05\n",
      "                                left:X_6 <= -1 ? 0.002382097620192966\n",
      "                                                                left:X_8 <= -1 ? 0.07438016528925631\n",
      "                                                                                                                                left:1\n",
      "                                                                                                                                right:1\n",
      "                                                                right:1\n",
      "                                right:1\n",
      "        right:X_0 <= -1 ? 0.0003174138011578509\n",
      "                left:X_28 <= 0 ? 0.002007557831563603\n",
      "                                left:X_6 <= 0 ? 0.016122798762066848\n",
      "                                                                left:X_23 <= -1 ? 0.05619363510232411\n",
      "                                                                                                                                left:1\n",
      "                                                                                                                                right:1\n",
      "                                                                right:X_27 <= -1 ? 0.00600865245954162\n",
      "                                                                                                                                left:1\n",
      "                                                                                                                                right:1\n",
      "                                right:X_11 <= -1 ? 0.0006366994339795026\n",
      "                                                                left:1\n",
      "                                                                right:X_27 <= -1 ? 0.005198305737389081\n",
      "                                                                                                                                left:1\n",
      "                                                                                                                                right:1\n",
      "                right:X_13 <= 0 ? 4.5058945180521254e-05\n",
      "                                left:X_19 <= -1 ? 0.00012212237594771969\n",
      "                                                                left:X_21 <= -1 ? 0.010625276653243906\n",
      "                                                                                                                                left:1\n",
      "                                                                                                                                right:1\n",
      "                                                                right:X_28 <= -1 ? 9.061343568107609e-05\n",
      "                                                                                                                                left:1\n",
      "                                                                                                                                right:1\n",
      "                                right:1\n"
     ]
    }
   ],
   "source": [
    "#plotting\n",
    "classifier.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "43542e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "picking best depth:  3 with accuracy  0.9635036496350365\n",
      "Accuracy: 0.9343065693430657\n"
     ]
    }
   ],
   "source": [
    "file_path = 'BCP.csv'\n",
    "data = pd.read_csv(file_path, skiprows=1, header=None)\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values.reshape(-1, 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=41)\n",
    "\n",
    "# Your classifier's fit and predict methods should work as intended if implemented correctly\n",
    "\n",
    "classifier = DecisionTreeClassifier(min_samples_split=2, max_depth=puring(X_train, y_train))\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test) \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "bcp_dt_p  = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2599cf76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_2 <= 2 ? 0.3487699066940749\n",
      " left:X_1 <= 6 ? 0.025447176988002626\n",
      "  left:X_6 <= 4 ? 0.008622488956713158\n",
      "    left:2\n",
      "    right:X_1 <= 3 ? 0.3173553719008265\n",
      "        left:2\n",
      "        right:4\n",
      "  right:X_6 <= 1 ? 0.20833333333333334\n",
      "    left:X_3 <= 2 ? 0.4444444444444444\n",
      "        left:2\n",
      "        right:4\n",
      "    right:4\n",
      " right:X_3 <= 2 ? 0.0798383566669814\n",
      "  left:X_1 <= 5 ? 0.3046875\n",
      "    left:2\n",
      "    right:4\n",
      "  right:X_2 <= 4 ? 0.011560234225791152\n",
      "    left:X_6 <= 3 ? 0.10528573584254902\n",
      "        left:2\n",
      "        right:4\n",
      "    right:X_0 <= 242970 ? 0.002417433649135034\n",
      "        left:4\n",
      "        right:4\n"
     ]
    }
   ],
   "source": [
    "classifier.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1a1a91f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "picking best depth:  8 with accuracy  0.6703296703296703\n",
      "Accuracy: 0.6593406593406593\n"
     ]
    }
   ],
   "source": [
    "file_path = 'new_arrhy.csv'\n",
    "data = pd.read_csv(file_path, skiprows=1, header=None)\n",
    "X = data.iloc[:, 1:-1].values\n",
    "y = data.iloc[:, -1].values.reshape(-1, 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=41)\n",
    "\n",
    "# Your classifier's fit and predict methods should work as intended if implemented correctly\n",
    "\n",
    "classifier = DecisionTreeClassifier(min_samples_split=2, max_depth=puring(X_train, y_train))\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test) \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "arrh_dt_p  = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0f139dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_222 <= 0.9 ? 0.06665457176492173\n",
      " left:X_275 <= 0.3 ? 0.060918986699485034\n",
      "  left:X_255 <= -0.5 ? 0.15560044954165708\n",
      "    left:X_4 <= 118.0 ? 0.11819021237303784\n",
      "        left:X_1 <= 156.0 ? 0.4444444444444444\n",
      "                left:2.0\n",
      "                right:1.0\n",
      "        right:2.0\n",
      "    right:X_3 <= 121.0 ? 0.13284499054820398\n",
      "        left:X_74 <= 24.0 ? 0.14222962382445148\n",
      "                left:X_110 <= 0.0 ? 0.15143876337693218\n",
      "                                left:X_11 <= 57.0 ? 0.13228235294117652\n",
      "                                                                left:X_261 <= -7.3 ? 0.19134948096885818\n",
      "                                                                                                                                left:X_8 <= -10.0 ? 0.31999999999999995\n",
      "                                                                                                                                                                                                                                                                left:2.0\n",
      "                                                                                                                                                                                                                                                                right:6.0\n",
      "                                                                                                                                right:X_99 <= 24.0 ? 0.20833333333333331\n",
      "                                                                                                                                                                                                                                                                left:16.0\n",
      "                                                                                                                                                                                                                                                                right:1.0\n",
      "                                                                right:X_2 <= 82.0 ? 0.22916666666666674\n",
      "                                                                                                                                left:X_1 <= 105.0 ? 0.2777777777777777\n",
      "                                                                                                                                                                                                                                                                left:5.0\n",
      "                                                                                                                                                                                                                                                                right:16.0\n",
      "                                                                                                                                right:X_0 <= 0.0 ? 0.5\n",
      "                                                                                                                                                                                                                                                                left:1.0\n",
      "                                                                                                                                                                                                                                                                right:15.0\n",
      "                                right:3.0\n",
      "                right:X_136 <= 32.0 ? 0.26446280991735543\n",
      "                                left:X_0 <= 0.0 ? 0.3333333333333334\n",
      "                                                                left:15.0\n",
      "                                                                right:X_1 <= 133.0 ? 0.5\n",
      "                                                                                                                                left:16.0\n",
      "                                                                                                                                right:2.0\n",
      "                                right:4.0\n",
      "        right:9.0\n",
      "  right:X_13 <= 58.0 ? 0.06625289953896918\n",
      "    left:X_264 <= 0.6 ? 0.1953816237238697\n",
      "        left:X_254 <= 0.3 ? 0.15570934256055358\n",
      "                left:X_0 <= 0.0 ? 0.5\n",
      "                                left:10.0\n",
      "                                right:16.0\n",
      "                right:6.0\n",
      "        right:X_0 <= 0.0 ? 0.31999999999999984\n",
      "                left:1.0\n",
      "                right:6.0\n",
      "    right:X_110 <= 20.0 ? 0.05696896771348364\n",
      "        left:X_13 <= 101.0 ? 0.04347961231510966\n",
      "                left:X_235 <= -1.0 ? 0.04442637172041847\n",
      "                                left:X_2 <= 70.0 ? 0.24489795918367352\n",
      "                                                                left:10.0\n",
      "                                                                right:15.0\n",
      "                                right:X_74 <= 24.0 ? 0.031458411895411015\n",
      "                                                                left:X_3 <= 103.0 ? 0.019548440762098163\n",
      "                                                                                                                                left:X_252 <= 0.6 ? 0.018653580636550787\n",
      "                                                                                                                                                                                                                                                                left:1.0\n",
      "                                                                                                                                                                                                                                                                right:10.0\n",
      "                                                                                                                                right:X_6 <= 159.0 ? 0.2962962962962963\n",
      "                                                                                                                                                                                                                                                                left:10.0\n",
      "                                                                                                                                                                                                                                                                right:1.0\n",
      "                                                                right:X_3 <= 84.0 ? 0.3395061728395061\n",
      "                                                                                                                                left:4.0\n",
      "                                                                                                                                right:X_9 <= 12.0 ? 0.375\n",
      "                                                                                                                                                                                                                                                                left:1.0\n",
      "                                                                                                                                                                                                                                                                right:16.0\n",
      "                right:5.0\n",
      "        right:X_165 <= 0.6 ? 0.20888888888888912\n",
      "                left:X_5 <= 401.0 ? 0.23999999999999985\n",
      "                                left:3.0\n",
      "                                right:X_1 <= 165.0 ? 0.5\n",
      "                                                                left:6.0\n",
      "                                                                right:2.0\n",
      "                right:X_1 <= 169.0 ? 0.31999999999999995\n",
      "                                left:X_0 <= 0.0 ? 0.3333333333333334\n",
      "                                                                left:14.0\n",
      "                                                                right:X_1 <= 127.0 ? 0.5\n",
      "                                                                                                                                left:5.0\n",
      "                                                                                                                                right:15.0\n",
      "                                right:16.0\n",
      " right:X_11 <= 75.0 ? 0.09766951942067148\n",
      "  left:X_236 <= -26.5 ? 0.10078786977850446\n",
      "    left:X_1 <= 165.0 ? 0.3333333333333334\n",
      "        left:6.0\n",
      "        right:X_1 <= 174.0 ? 0.5\n",
      "                left:2.0\n",
      "                right:1.0\n",
      "    right:X_111 <= 56.0 ? 0.06386999244142086\n",
      "        left:X_181 <= -5.0 ? 0.07133058984910856\n",
      "                left:1.0\n",
      "                right:10.0\n",
      "        right:1.0\n",
      "  right:X_0 <= 0.0 ? 0.25\n",
      "    left:X_1 <= 110.0 ? 0.5\n",
      "        left:5.0\n",
      "        right:14.0\n",
      "    right:X_1 <= 130.0 ? 0.5\n",
      "        left:16.0\n",
      "        right:15.0\n"
     ]
    }
   ],
   "source": [
    "classifier.print_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7c3a60",
   "metadata": {},
   "source": [
    "After evaluating the results of the aforementioned decision tree code, it is clear that pruning improves speed for both the web-phishing and BCP datasets. However, there is a significant decline in accuracy for the arrhythmia dataset, which might be ascribed to numerous factors:\n",
    "\n",
    "- The decision tree has the potential to overfit, meaning that the model becomes overly suited to the training data.\n",
    "\n",
    "- The pruning procedure may mistakenly delete relevant subtrees, resulting in a loss of essential data required for accurate predictions.\n",
    "\n",
    "- The intrinsic intricacy of the arrhythmia dataset might also be a contributing issue, since it may need a more sophisticated methodology to model adequately.\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c7fb9a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8959746720940751 0.9249208502939846 0.937584803256445\n",
      "0.8978102189781022 0.9197080291970803 0.9343065693430657\n",
      "0.02197802197802198 0.6703296703296703 0.6593406593406593\n"
     ]
    }
   ],
   "source": [
    "print(web_DS, web_dt, web_dt_p)\n",
    "print(bcp_DS, bcp_dt, bcp_dt_p)\n",
    "print(arrh_DS, arrh_dt, arrh_dt_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3350ab2",
   "metadata": {},
   "source": [
    "After assessing the performance of decision stump, decision tree, and pruned decision tree on three datasets, it was discovered that the models performed the worst on the arrhythmia dataset compared to the other two. A t-test would be ideal for appropriately assessing and quantifying performance differences in the arrhythmia dataset. This statistical test will aid in identifying the importance of the performance disparities seen across the models, particularly for the arrhythmia dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "29812a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using cv =3 to save time\n",
    "def cross_validate_decision_stump(X, y, cv=3):\n",
    "    # Flatten y to ensure it's a 1D array\n",
    "    y = y.ravel()\n",
    "    score = []\n",
    "    # Initialize KFold cross-validator\n",
    "    kf = KFold(n_splits=cv, shuffle=True, random_state=42)    \n",
    "    # Loop over each split\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        # Split the data into training and testing sets for the current fold\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Initialize and fit the decision stump on the training data\n",
    "        stump = DecisionStump()\n",
    "        stump.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict on the testing data\n",
    "        y_pred = stump.predict(X_test)\n",
    "        \n",
    "        # Calculate the accuracy and store it\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        score.append(accuracy)\n",
    "    return score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8759b2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_decision_tree(X, y, cv=3):\n",
    "    # Initialize KFold cross-validator with 'cv' splits\n",
    "    kf = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "    score = []\n",
    "    # Loop over each fold\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        # Split data into training and testing sets for the current fold\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Initialize and fit the decision tree classifier\n",
    "        classifier = DecisionTreeClassifier(min_samples_split=2, max_depth=5)\n",
    "        classifier.fit(X_train, y_train.ravel())\n",
    "\n",
    "        # Predict on the test set and calculate accuracy\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        # Store the accuracy score\n",
    "        score.append(accuracy)\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "be93402b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_decision_tree_p(X, y, cv=3):\n",
    "    # Initialize KFold cross-validator with 'cv' splits\n",
    "    kf = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "    score = []\n",
    "    # Loop over each fold\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        # Split data into training and testing sets for the current fold\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Initialize and fit the decision tree classifier\n",
    "        classifier = DecisionTreeClassifier(min_samples_split=2, max_depth=puring(X_train, y_train))\n",
    "        classifier.fit(X_train, y_train.ravel())\n",
    "\n",
    "        # Predict on the test set and calculate accuracy\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        score.append(accuracy)\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "816a665a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paired t-test between Decision Stump and Unpruned DT on Web dataset: p-value = 0.0093\n",
      "picking best depth:  6 with accuracy  0.6447368421052632\n",
      "picking best depth:  4 with accuracy  0.6973684210526315\n",
      "picking best depth:  4 with accuracy  0.75\n",
      "Paired t-test between Unpruned DT and Pruned DT on Web dataset: p-value = 0.6206\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "# to saving times, that I'll using cv where kfold = 3. \n",
    "ds_score = []\n",
    "dt_score =[]\n",
    "dt_p_score = []\n",
    "\n",
    "file_path = 'new_arrhy.csv'\n",
    "data = pd.read_csv(file_path, skiprows=1, header=None)\n",
    "X = data.iloc[:, 1:-1].values\n",
    "y = data.iloc[:, -1].values.reshape(-1, 1)\n",
    "ds_score = cross_validate_decision_stump(X,y)\n",
    "dt_score = cross_validate_decision_tree(X,y)\n",
    "# print(ds_score, dt_score)\n",
    "# Comparing Decision Stump vs. Unpruned Decision Tree\n",
    "t_stat, p_value = ttest_rel(ds_score, dt_score)\n",
    "print(f\"Paired t-test between Decision Stump and Unpruned DT on Web dataset: p-value = {p_value:.4f}\")\n",
    "\n",
    "dt_p_score = cross_validate_decision_tree_p(X,y)\n",
    "# Comparing Unpruned Decision Tree vs. Pruned Decision Tree\n",
    "t_stat, p_value = ttest_rel(dt_score, dt_p_score)\n",
    "print(f\"Paired t-test between Unpruned DT and Pruned DT on Web dataset: p-value = {p_value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a548c218",
   "metadata": {},
   "source": [
    "The p-value for Decison Stump vs. Decison Tree without Purning is 0.0093, which is less than the standard p-value of 0.05. This implies that their accuracy is not only attributable to random fluctuations in the data. It strongly implies that one model outperforms the other in this dataset. According to the accuracy performance of decison stump and decison tree discussed above, the observed performance difference is unlikely to be due to chance; there is a true underlying difference in how these two models predict arrhythmia events.\n",
    "\n",
    "The p-value for Decison tree without purning and Decison tree with purning is 0.6206, indicating that on the arrhythmia dataset, the variation in performance between these two methods might be due to chance. Also, the p-value is significantly higher than usual (0.05), indicating that there is no significant difference in the efficacy of the Unpruned DT compared to the Pruned DT in this dataset. Essentially, trimming did not result in a statistically significant increase or reduction in model performance.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
